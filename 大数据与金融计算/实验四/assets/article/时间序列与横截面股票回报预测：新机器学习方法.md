# 时间序列与横截面股票回报预测：新机器学习方法

## 概述

本文介绍了如何利用机器学习方法（特别是弹性网络 Elastic Net）来改进股票回报预测。主要包括两大方向：

1. 时间序列预测 - 预测整体市场超额回报
2. 横截面预测 - 预测不同公司股票之间的回报差异

## 主要方法

### 预测回归基础

基本预测回归模型为：

```
rt = α + βxj,t-1 + εt
```

其中：

- rt 是 t 期股票市场指数超额回报（超过无风险收益）
- xj,t 是预测变量
- εt 是扰动项

### 传统预测方法的问题

传统 OLS 多元预测回归模型容易过拟合，特别是当使用多个预测变量时，导致样本外预测效果差。

### 简单组合预测

一个改进方法是简单组合预测，计算方式为：

```
r̂C(t+1|t) = (1/J) * Σ(j=1 to J) r̂(j)(t+1|t)
```

这是多个单变量预测的平均值，对预测参数进行了强收缩，有助于避免过拟合。

### 弹性网络 (Elastic Net)

弹性网络结合了 L1（LASSO）和 L2（岭回归）正则化，目标函数为：

```
arg min[α,β1,...,βJ∈R] [ (1/2t) * Σ(s=1 to t) (rs - α - Σ(j=1 to J) βjxj,s-1)² + λPδ(β1,...,βJ) ]
```

其中：

```
Pδ(β1,...,βJ) = 0.5(1-δ) * Σ(j=1 to J) βj² + δ * Σ(j=1 to J) |βj|
```

- λ ≥ 0 是控制收缩程度的正则化参数
- 0 ≤ δ ≤ 1 是混合 L1 和 L2 惩罚的参数

### 组合弹性网络 (Combination Elastic Net, C-ENet)

结合了简单组合预测和弹性网络的优点：

1. 先计算各个单变量预测
2. 使用弹性网络选择最相关的单变量预测
3. 对选中的预测进行平均

计算方式：

```
r̂C-ENet(t+1|t) = (1/|Jt|) * Σ(j∈Jt) r̂(j)(t+1|t)
```

其中 Jt 是通过弹性网络在 Granger-Ramanathan 回归中选出的预测变量集合。

## Python 代码示例

### 1. 简单预测回归

```python
import numpy as np
from sklearn.linear_model import LinearRegression

# 模拟数据
np.random.seed(42)
t = 100
x = np.random.normal(0, 1, t)
r = 0.5 * x + np.random.normal(0, 1, t)  # 真实关系: r = 0.5*x + 噪声

# 单变量预测回归
def predictive_regression(r, x, t_train):
    # 使用t_train数据进行训练
    model = LinearRegression()
    model.fit(x[:t_train].reshape(-1, 1), r[:t_train])

    # 使用当前值预测下一期
    next_pred = model.predict(np.array([x[t_train]]).reshape(-1, 1))[0]
    return next_pred

# 计算一个样本外预测
t_train = 80
pred = predictive_regression(r, x, t_train)
print(f"预测值: {pred:.4f}, 实际值: {r[t_train+1]:.4f}")
```

### 2. 实现弹性网络预测

```python
from sklearn.linear_model import ElasticNet

# 模拟多个预测变量
X = np.random.normal(0, 1, (t, 5))  # 5个预测变量
r = 0.5 * X[:, 0] + 0.3 * X[:, 2] + np.random.normal(0, 1, t)  # 只有两个变量真正相关

# 弹性网络预测
def enet_prediction(r, X, t_train, alpha=0.5, l1_ratio=0.5):
    model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)
    model.fit(X[:t_train], r[:t_train])

    next_pred = model.predict(X[t_train].reshape(1, -1))[0]
    return next_pred, model.coef_

# 计算一个样本外预测
t_train = 80
pred, coefs = enet_prediction(r, X, t_train)
print(f"弹性网络预测值: {pred:.4f}, 实际值: {r[t_train+1]:.4f}")
print(f"弹性网络系数: {coefs}")
```

### 3. 实现组合弹性网络预测

```python
import numpy as np
from sklearn.linear_model import LinearRegression, ElasticNet

# 模拟多个预测变量
np.random.seed(42)
t = 100
X = np.random.normal(0, 1, (t, 5))  # 5个预测变量
r = 0.5 * X[:, 0] + 0.3 * X[:, 2] + np.random.normal(0, 1, t)  # 只有两个变量真正相关

# 计算单变量预测
def univariate_predictions(r, X, t_train):
    preds = []
    for j in range(X.shape[1]):
        model = LinearRegression()
        model.fit(X[:t_train, j].reshape(-1, 1), r[:t_train])
        next_pred = model.predict(np.array([X[t_train, j]]).reshape(-1, 1))[0]
        preds.append(next_pred)
    return np.array(preds)

# 实现C-ENet预测
def c_enet_prediction(r, X, t_train, t_hold=10, alpha=0.5, l1_ratio=0.5):
    # 计算所有单变量预测
    all_uni_preds = []
    for t in range(t_train, t_train+t_hold):
        uni_preds = univariate_predictions(r, X, t)
        all_uni_preds.append(uni_preds)

    # 创建训练数据用于Granger-Ramanathan回归
    X_hold = np.array(all_uni_preds[:-1])
    y_hold = r[t_train+1:t_train+t_hold]

    # 使用弹性网络选择最相关的预测
    model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, positive=True)
    model.fit(X_hold, y_hold)

    # 找出选中的预测
    selected_indices = np.where(model.coef_ > 0)[0]

    # 如果没有选中任何预测,使用全部
    if len(selected_indices) == 0:
        selected_indices = np.arange(X.shape[1])

    # 计算最新一期的单变量预测
    latest_uni_preds = univariate_predictions(r, X, t_train+t_hold-1)

    # 只使用选中的预测并平均
    c_enet_pred = np.mean(latest_uni_preds[selected_indices])

    return c_enet_pred, selected_indices

# 计算C-ENet预测
t_train = 70
c_enet_pred, selected = c_enet_prediction(r, X, t_train)
print(f"C-ENet预测值: {c_enet_pred:.4f}, 实际值: {r[t_train+10]:.4f}")
print(f"选中的预测变量索引: {selected}")
```

## 数学运算举例

### 简单组合预测举例

假设我们有 3 个单变量预测模型，对下一期回报的预测分别为：1.2%, 0.8%, 1.5%

简单组合预测为: (1.2% + 0.8% + 1.5%) / 3 = 1.17%

### 弹性网络正则化举例

假设有两个预测变量，弹性网络的惩罚项为：

对于 β1 = 0.5, β2 = -0.3, δ = 0.5:

Pδ(β1,β2) = 0.5(1-0.5)[(0.5)² + (-0.3)²] + 0.5[|0.5| + |-0.3|]
= 0.25[0.25 + 0.09] + 0.5[0.5 + 0.3]
= 0.25(0.34) + 0.5(0.8)
= 0.085 + 0.4
= 0.485

这个惩罚项将被添加到损失函数中，使系数收缩到合适的大小。

### 组合弹性网络预测举例

假设我们有 5 个单变量预测：1.2%, 0.8%, 1.5%, -0.3%, 0.5%
弹性网络选择了索引为 0, 2, 4 的预测变量

组合弹性网络预测为: (1.2% + 1.5% + 0.5%) / 3 = 1.07%

## 结论

组合弹性网络方法比传统 OLS 和简单组合预测都表现更好：

1. 相比 OLS 预测，它通过收缩避免了过拟合
2. 相比简单组合预测，它通过选择相关变量减少了"过度收缩"
3. 为投资者提供了更准确的回报预测，带来显著的经济价值

这种方法既适用于时间序列预测（预测整体市场回报），也适用于横截面预测（预测不同股票之间的回报差异）。
